# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hVL_nqeQbmX0uHhdojw2WubErGph8Fkr
"""

import tensorflow as tf

"""**Step 1 : Importing Libraries**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
import numpy as np

"""**STEP 2 : Sample Dataset**"""

texts = [
     "I love this movie",
     "This film was terrible",
     "Amazing experience",
     "Worst movie ever",
     "I really liked it",
     "Awful and boring",
]
labels = [1,0,1,0,1,0]

"""**Step 3 : Define Preprocessing Parameters**"""

vocab_size = 1000
  embedding_dim = 64
  max_length = 10
  trunc_type = 'post'
  padding_type = 'post'
  oov_tok = '<OOV>'

"""**Step 4 : Tokenize and Pad the Text**"""

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
   tokenizer.fit_on_texts(texts)
    sequences = tokenizer.texts_to_sequences(texts)
   padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

"""**Step 5 : Prepare Labels**"""

labels = np.array(labels)

"""**Step 6 : Build the LSTM Model**"""

model = Sequential([
      Embedding(vocab_size, embedding_dim),
      LSTM(64, return_sequences=False),
      Dropout(0.5),
      Dense(32, activation='relu'),
      Dense(1, activation='sigmoid')
])

"""Step 7 :"""

